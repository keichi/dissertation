@article{Arap2014,
author = {Arap, Omer and Brown, Geoffrey and Himebaugh, Bryce and Swany, Martin},
doi = {10.1007/978-3-319-09873-9_53},
file = {:Users/keichi/Documents/paper/Lecture Notes in Computer Science/Arap et al. - 2014 - Software Defined Multicasting for MPI Collective Operation Offloading with the NetFPGA.pdf:pdf},
journal = {Lecture Notes in Computer Science},
mendeley-groups = {INDIS16},
pages = {632--643},
publisher = {Springer International Publishing},
title = {{Software Defined Multicasting for MPI Collective Operation Offloading with the NetFPGA}},
volume = {8632},
year = {2014}
}
@article{Bird2011,
abstract = {Following the first full year of Large Hadron Collider (LHC) data taking, the Worldwide LHC Computing Grid (WLCG) computing environment built to support LHC data processing and analysis has been validated. In this review, I discuss the rationale for the design of a distributed system and describe how this environment was constructed and deployed through the use of grid computing technologies. I discuss the experience with large-scale testing and operation with real accelerator data, which shows that expectations have been met and sometimes exceeded. The computing system's key achievements are that (a) the WLCG infrastructure is distributed and makes use of all the dispersed resources, (b) the experiments' computing models are also distributed and can make excellent use of the infrastructure, and (c) the computing system has enabled physics output in a very short time. Finally, I present prospects for the future evolution of the WLCG infrastructure.},
author = {Bird, Ian},
doi = {10.1146/annurev-nucl-102010-130059},
file = {:Users/keichi/Documents/paper/Annual Review of Nuclear and Particle Science/Bird - 2011 - Computing for the Large Hadron Collider.pdf:pdf},
journal = {Annual Review of Nuclear and Particle Science},
keywords = {LCG,WLCG,distributed,grid},
mendeley-groups = {INDIS16},
number = {1},
pages = {99--118},
publisher = {Annual Reviews},
title = {{Computing for the Large Hadron Collider}},
volume = {61},
year = {2011}
}
@inproceedings{Cheng2014,
abstract = {Big-Data applications need to shuffle their data over a network in a very large amount. The ability to efficiently allocate network resources to quickly finish the shuffle greatly affects the overall processing speed of Big-Data applications. The recent emergence of software-defined networking (SDN) technology makes it easier for the network to integrate with a Big- Data application. The network can allocate network resources based on an application's run-time requirements to accelerate the speed of Big-Data delivery. In this paper, we used Hadoop as a Big-Data application platform and designed an application-aware SDN routing scheme for Hadoop to accelerate its MapReduce data shuffling over a network. Our results show that our method can outperform the ECMP-RR scheme by up to 20{\%} and outperform the Spanning Tree method and the Floodlight OpenFlow controller by up to 70{\%}.},
author = {Cheng, Li-wei and Wang, Shie-yuan},
booktitle = {Proceedings of the IEEE Global Communications Conference - {GLOBECOM} 2015},
doi = {10.1109/GLOCOM.2014.7417577},
file = {:Users/keichi/Documents/paper/Proceedings of the IEEE Global Communications Conference - GLOBECOM 2015/Cheng, Wang - 2015 - Application-Aware SDN Routing for Big Data Networking.pdf:pdf},
keywords = {Application-Aware SDN Routing for Big Data Network},
mendeley-groups = {INDIS16},
pages = {1--6},
title = {{Application-Aware SDN Routing for Big Data Networking}},
year = {2015}
}
@article{Dashdavaa2014,
author = {Dashdavaa, Khureltulga and Date, Susumu and Yamanaka, Hiroaki and Kawai, Eiji and Watashiba, Yasuhiro and Ichikawa, Kohei and Abe, Hirotake and Shimojo, Shinji},
doi = {10.1007/978-3-642-54420-0_86},
journal = {Lecture Notes in Computer Science},
mendeley-groups = {INDIS16},
pages = {885--894},
publisher = {Springer Berlin Heidelberg},
title = {{Architecture of a High-speed MPI\_Bcast Leveraging Software-defined Network}},
volume = {8374},
year = {2014}
}
@article{Gropp2002,
author = {Gropp, William},
doi = {10.1007/3-540-45825-5_5},
journal = {Lecture Notes in Computer Science},
mendeley-groups = {INDIS16},
pages = {7},
publisher = {Springer Berlin Heidelberg},
title = {{MPICH2: A new start for MPI implementations}},
volume = {2474},
year = {2002}
}
@inproceedings{Huang2006,
author = {Huang, W. and Santhanaraman, G. and Jin, H.-W. and Gao, Q. and Panda, D.K.},
booktitle = {Proceedings of the Sixth {IEEE} International Symposium on Cluster Computing and the Grid - {CCGRID}'06},
doi = {10.1109/CCGRID.2006.32},
mendeley-groups = {INDIS16},
pages = {43--48},
title = {{Design of High Performance MVAPICH2: MPI2 over InfiniBand}},
year = {2006}
}
@misc{InfiniBand2015,
author = {{InfiniBand Trade Association}},
mendeley-groups = {INDIS16},
title = {{InfiniBand Architecture Specification Release 1.3}},
year = {2015}
}
@article{Kamil2010,
author = {Kamil, Shoaib and Oliker, Leonid and Pinar, Ali and Shalf, John},
doi = {10.1109/TPDS.2009.61},
file = {:Users/keichi/Documents/paper/IEEE Transactions on Parallel and Distributed Systems/Kamil et al. - 2010 - Communication Requirements and Interconnect Optimization for High-End Scientific Applications(2).pdf:pdf},
journal = {{IEEE} Transactions on Parallel and Distributed Systems},
keywords = {FFT-based solver methods,Interconnections,active commodity switch,exascale computing,finite difference methods,fit-tree approach,fully connected network,high-end scientific applications,hybrid flexibly assignable switch topology,interconnect optimization,lattice Boltzmann methods,multiprocessor interconnection networks,natural sciences computing,particle-in-cell methods,particle-mesh ewald methods,passive commodity switch,performance analysis.,petascale computing,reconfigurable networks,scientific computing,sparse linear algebra methods,topology,ultrascale systems},
mendeley-groups = {INDIS16},
month = feb,
number = {2},
pages = {188--202},
publisher = {IEEE},
title = {{Communication Requirements and Interconnect Optimization for High-End Scientific Applications}},
volume = {21},
year = {2010}
}
@inproceedings{Kamil2007,
author = {Kamil, Shoaib and Pinar, Ali and Gunter, Daniel and Lijewski, Michael and Oliker, Leonid and Shalf, John},
booktitle = {Proceedings of the 4th International Conference on Computing Frontiers - {CF} '07},
doi = {10.1145/1242531.1242559},
file = {:Users/keichi/Documents/paper/Proceedings of the 4th International Conference on Computing Frontiers - CF '07/Kamil et al. - 2007 - Reconfigurable Hybrid Interconnection for Static and Dynamic Scientific Applications.pdf:pdf},
keywords = {adaptive mesh refinement,feasibility,hybrid interconnects,petascale},
mendeley-groups = {INDIS16},
pages = {183--194},
title = {{Reconfigurable Hybrid Interconnection for Static and Dynamic Scientific Applications}},
year = {2007}
}
@incollection{Squyres2005,
author = {{M. Squyres}, Jeffrey and Lumsdaine, Andrew},
booktitle = {Component Models and Systems for Grid Applications},
doi = {10.1007/0-387-23352-0_11},
mendeley-groups = {INDIS16},
pages = {167--185},
publisher = {Kluwer Academic Publishers},
title = {{The Component Architecture of Open MPI: Enabling Third-Party Collective Algorithms}},
year = {2005}
}
@article{McKeown2008,
abstract = {This whitepaper proposes OpenFlow: a way for researchers to run experimental protocols in the networks they use ev- ery day. OpenFlow is based on an Ethernet switch, with an internal flow-table, and a standardized interface to add and remove flow entries. Our goal is to encourage network- ing vendors to add OpenFlow to their switch products for deployment in college campus backbones and wiring closets. We believe that OpenFlow is a pragmatic compromise: on one hand, it allows researchers to run experiments on hetero- geneous switches in a uniform way at line-rate and with high port-density; while on the other hand, vendors do not need to expose the internal workings of their switches. In addition to allowing researchers to evaluate their ideas in real-world traffic settings, OpenFlow could serve as a useful campus component in proposed large-scale testbeds like GENI. Two buildings at Stanford University will soon run OpenFlow networks, using commercial Ethernet switches and routers. We will work to encourage deployment at other schools; and We encourage you to consider deploying OpenFlow in your university network too.},
author = {McKeown, Nick and Anderson, Tom and Balakrishnan, Hari and Parulkar, Guru and Peterson, Larry and Rexford, Jennifer and Shenker, Scott and Turner, Jonathan},
doi = {10.1145/1355734.1355746},
file = {:Users/keichi/Documents/paper/ACM SIGCOMM Computer Communication Review/McKeown et al. - 2008 - OpenFlow Enabling Innovation in Campus Networks.pdf:pdf},
journal = {{ACM} {SIGCOMM} Computer Communication Review},
keywords = {ethernet switch,flow-based,virtualization},
mendeley-groups = {INDIS16},
month = mar,
number = {2},
pages = {69--74},
publisher = {ACM},
title = {{OpenFlow: Enabling Innovation in Campus Networks}},
volume = {38},
year = {2008}
}
@inproceedings{Mekky2014,
author = {Mekky, Hesham and Hao, Fang and Mukherjee, Sarit and Zhang, Zhi-Li and Lakshman, T.V.},
booktitle = {Proceedings of the Third Workshop on Hot Topics in Software Defined Networking - {HotSDN} '14},
doi = {10.1145/2620728.2620735},
file = {:Users/keichi/Documents/paper/Proceedings of the Third Workshop on Hot Topics in Software Defined Networking - HotSDN '14/Mekky et al. - 2014 - Application-aware Data Plane Processing in SDN.pdf:pdf},
keywords = {data plane,open vswitch,openflow,software-defined networking},
mendeley-groups = {INDIS16},
pages = {13--18},
title = {{Application-aware Data Plane Processing in SDN}},
year = {2014}
}
@misc{MPIForum2012,
author = {{MPI Forum}},
mendeley-groups = {INDIS16},
title = {{MPI: A Message-Passing Interface Standard}},
url = {https://www.mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf},
year = {2012}
}
@misc{OhioStateUniversity2016,
author = {{Ohio State University}},
mendeley-groups = {INDIS16},
title = {{MVAPICH :: Benchmarks}},
url = {http://mvapich.cse.ohio-state.edu/benchmarks/},
year = {2016}
}
@article{Rabenseifner2004,
author = {Rabenseifner, Rolf},
doi = {10.1007/978-3-540-24685-5_1},
file = {:Users/keichi/Documents/paper/Lecture Notes in Computer Science/Rabenseifner - 2004 - Optimization of Collective Reduction Operations.pdf:pdf},
journal = {Lecture Notes in Computer Science},
keywords = {Collective Operations,MPI,Message Passing,Reduction},
mendeley-groups = {INDIS16},
pages = {1--9},
publisher = {Springer Berlin Heidelberg},
title = {{Optimization of Collective Reduction Operations}},
volume = {3036},
year = {2004}
}
@book{Rosen2013,
author = {Rosen, Rami},
mendeley-groups = {INDIS16},
publisher = {Apress},
title = {{Linux Kernel Networking: Implementation and Theory}},
year = {2013}
}
@misc{Ryu2014,
author = {{Ryu SDN Framework Community}},
mendeley-groups = {INDIS16},
title = {{Ryu SDN Framework}},
url = {https://osrg.github.io/ryu/},
year = {2014}
}
@inproceedings{Schneider2013,
author = {Schneider, Timo and Hoefler, Torsten and Grant, Ryan E. and Barrett, Brian W. and Brightwell, Ron},
booktitle = {Proceedings of the 42nd International Conference on Parallel Processing - ICPP 2013},
doi = {10.1109/ICPP.2013.73},
file = {:Users/keichi/Documents/paper/Proceedings of the 42nd International Conference on Parallel Processing - ICPP 2013/Schneider et al. - 2013 - Protocols for Fully Offloaded Collective Operations on Accelerated Network Adapters.pdf:pdf},
isbn = {978-0-7695-5117-3},
keywords = {Algorithm design and analysis,Portals,Portals 4 specification,Protocols,Radiation detectors,Receivers,Schedules,Semantics,abstract communication graphs,collective offload,communication hardware,communication patterns offloading,communication stack,directed graphs,fully offloaded collective operations,high-performance NIC,high-performance networks,middleware,multiprocessing systems,network adapter,network adapters,offloaded communication schedules,offloading interfaces,parallel processing,portals,scheduling},
mendeley-groups = {INDIS16},
month = oct,
pages = {593--602},
publisher = {IEEE},
title = {{Protocols for Fully Offloaded Collective Operations on Accelerated Network Adapters}},
year = {2013}
}
@inproceedings{Takahashi2015,
author = {Takahashi, Keichi and Khureltulga, Dashdavaa and Munkhdorj, Baatarsuren and Kido, Yoshiyuki and Date, Susumu and Yamanaka, Hiroaki and Kawai, Eiji and Shimojo, Shinji},
booktitle = {Proceedings of the Fourth European Workshop on Software Defined Networks - {EWSDN} 2015},
doi = {10.1109/EWSDN.2015.72},
mendeley-groups = {INDIS16},
pages = {109--110},
title = {{Concept and Design of SDN-Enhanced MPI Framework}},
year = {2015}
}
@inproceedings{Takahashi2014,
author = {Takahashi, Keichi and Khureltulga, Dashdavaa and Watashiba, Yasuhiro and Kido, Yoshiyuki and Date, Susumu and Shimojo, Shinji},
booktitle = {Proceedings of the International Conference on High Performance Computing {\&} Simulation - {HPCS} 2014},
doi = {10.1109/HPCSim.2014.6903768},
mendeley-groups = {MPI,Past Papers/IPSJ OS,INDIS16},
pages = {784--792},
title = {{Performance Evaluation of SDN-enhanced MPI{\_}Allreduce on a Cluster System with Fat-tree Interconnect}},
year = {2014}
}
@inproceedings{Subramoni2016,
author = {Subramoni, Hari and Augustine, Albert Mathews and Arnold, Mark and Perkins, Jonathan and Lu, Xiaoyi and Hamidouche, Khaled and Panda, Dhabaleswar K.},
booktitle = {International Conference on High Performance Computing (ISC)},
doi = {10.1007/978-3-319-41321-1_16},
file = {:Users/keichi/Documents/Mendeley Desktop/Subramoni et al. - 2016 - INAM2 InfiniBand Network Analysis and Monitoring with MPI.pdf:pdf;:Users/keichi/Documents/Mendeley Desktop/subramoni-isc16-inam.pdf:pdf},
mendeley-groups = {HPCMASPA},
pages = {300--320},
title = {{INAM2: InfiniBand Network Analysis and Monitoring with MPI}},
year = {2016}
}
@article{Date2016,
author = {Date, Susumu and Abe, Hirotake and Khureltulga, Dashdavaa and Takahashi, Keichi and Kido, Yoshiyuki and Watashiba, Yasuhiro and U-chupala, Pongsakorn and Ichikawa, Kohei and Yamanaka, Hiroaki and Kawai, Eiji and Shimojo, Shinji},
journal = {International Journal of Information Technology},
mendeley-groups = {HPCMASPA},
number = {1},
title = {{SDN-accelerated HPC Infrastructure for Scientific Research}},
volume = {22},
year = {2016}
}
@misc{milc,
author = {{MIMD Lattice Computation Collaboration}},
mendeley-groups = {HPCMASPA},
title = {{MIMD Lattice Computation (MILC) Collaboration Home Page}},
url = {http://physics.indiana.edu/~sg/milc.html}
}
@article{Bailey1991,
abstract = {A new set of benchmarks has been developed for the performance evaluation of highly parallel supercomputers. These benchmarks consist of five parallel kernels and three simulated application benchmarks. Together they mimic the computation and data movement characteristics of large scale Computational Fluid Dynamics (CFD) applications. The principal distinguishing feature of these benchmarks is their 'pencil and paper' specification-all details of these benchmarks are specified only algorithmically. In this way many of the difficulties associated with conventional benchmarking approaches on highly parallel systems are avoided.},
author = {Bailey, D.H. and Barszcz, E. and Barton, J.T. and Browning, D.S. and Carter, R.L. and Dagum, L. and Fatoohi, R.A. and Frederickson, P.O. and Lasinski, T.A. and Schreiber, R.S. and Simon, H.D. and Venkatakrishnan, V. and Weeratunga, S.K.},
doi = {10.1177/109434209100500306},
file = {:Users/keichi/Documents/Mendeley Desktop/Bailey et al. - 1991 - The Nas Parallel Benchmarks.pdf:pdf},
isbn = {978-0-7695-3174-8},
journal = {International Journal of High Performance Computing Applications},
mendeley-groups = {HPCMASPA},
number = {3},
pages = {63--73},
title = {{The NAS Parallel Benchmarks}},
volume = {5},
year = {1991}
}
@article{Bastian2009,
abstract = {Gephi is an open source software for graph and network analysis. It uses a 3D render engine to display large networks in real-time and to speed up the exploration. A flexible and multi-task architecture brings new possibilities to work with complex data sets and produce valuable visual results.¬† We present several key features of Gephi in the context of interactive exploration and interpretation of networks. It provides easy and broad access to network data and allows for spatializing, filtering, navigating, manipulating and clustering. Finally, by presenting dynamic features of Gephi, we highlight key aspects of dynamic network visualization.},
author = {Bastian, Mathieu and Heymann, Sebastien and Jacomy, Mathieu},
doi = {10.1136/qshc.2004.010033},
journal = {Third International Conference on Weblogs and Social Media (ICWSM-09)},
keywords = {graph explor,network,network science,visualization},
mendeley-groups = {HPCMASPA},
pages = {361--362},
title = {{Gephi: An Open Source Software for Exploring and Manipulating Networks}},
year = {2009}
}
@article{Shannon2003,
abstract = {Cytoscape is an open source software project for integrating biomolecular interaction networks with high-throughput expression data and other molecular states into a unified conceptual framework. Although applicable to any system of molecular components and interactions, Cytoscape is most powerful when used in conjunction with large databases of protein-protein, protein-DNA, and genetic interactions that are increasingly available for humans and model organisms. Cytoscape's software Core provides basic functionality to layout and query the network; to visually integrate the network with expression profiles, phenotypes, and other molecular states; and to link the network to databases of functional annotations. The Core is extensible through a straightforward plug-in architecture, allowing rapid development of additional computational analyses and features. Several case studies of Cytoscape plug-ins are surveyed, including a search for interaction pathways correlating with changes in gene expression, a study of protein complexes involved in cellular recovery to DNA damage, inference of a combined physical/functional interaction network for Halobacterium, and an interface to detailed stochastic/kinetic gene regulatory models.},
author = {Shannon, Paul and Markiel, Andrew and Ozier, Owen and Baliga, Nitin S and Wang, Jonathan T and Ramage, Daniel and Amin, Nada and Schwikowski, Beno and Ideker, Trey},
doi = {10.1101/gr.1239303},
file = {:Users/keichi/Documents/Mendeley Desktop/Shannon et al. - 2003 - Cytoscape a software environment for integrated models of biomolecular interaction networks.pdf:pdf},
journal = {Genome Research},
mendeley-groups = {HPCMASPA},
number = {11},
pages = {2498--2504},
publisher = {Cold Spring Harbor Laboratory Press},
title = {{Cytoscape: A Software Environment for Integrated Models of Biomolecular Interaction Networks}},
volume = {13},
year = {2003}
}
@article{Brandes2013,
author = {Brandes, Ulrik and Eiglsperger, Markus and Lerner, J{\"{u}}rgen and Pich, Christian},
journal = {Handbook of Graph Drawing and Visualization},
mendeley-groups = {HPCMASPA},
pages = {517--541},
publisher = {CRC press},
title = {{Graph Markup Language (GraphML)}},
year = {2013}
}
@book{Gropp2014,
author = {Gropp, Willam and Lusk, Ewing and Skjellum, Anthony},
isbn = {9780262527392},
mendeley-groups = {HPCMASPA},
publisher = {The MIT Press},
title = {{Using MPI: Portable Parallel Programming with the Message-Passing Interface, Third Edition}},
year = {2014}
}
@inproceedings{Hoefler2010,
author = {Hoefler, Torsten and Schneider, Timo and Lumsdaine, Andrew},
booktitle = {19th International Symposium on High Performance Distributed Computing (HPDC '10)},
doi = {10.1145/1851476.1851564},
file = {:Users/keichi/Documents/Mendeley Desktop/Hoefler, Schneider, Lumsdaine - 2010 - LogGOPSim Simulating Large-scale Applications in the LogGOPS Model(2).pdf:pdf},
keywords = {gopsim,simulating large-scale applications in,the},
mendeley-groups = {HPCMASPA},
pages = {597--604},
title = {{LogGOPSim: Simulating Large-scale Applications in the LogGOPS Model}},
year = {2010}
}
@incollection{Knupfer2008,
author = {Kn{\"{u}}pfer, Andreas and Brunst, Holger and Doleschal, Jens and Jurenz, Matthias and Lieber, Matthias and Mickler, Holger and M{\"{u}}ller, Matthias S. and Nagel, Wolfgang E.},
booktitle = {Tools for High Performance Computing},
doi = {10.1007/978-3-540-68564-7_9},
file = {:Users/keichi/Documents/Mendeley Desktop/Kn{\"{u}}pfer et al. - 2008 - The Vampir Performance Analysis Tool-Set.pdf:pdf},
mendeley-groups = {HPCMASPA},
pages = {139--155},
title = {{The Vampir Performance Analysis Tool-Set}},
year = {2008}
}
@article{Shende2006,
author = {Shende, S. S. and Malony, Allen D.},
doi = {10.1177/1094342006064482},
journal = {International Journal of High Performance Computing Applications},
keywords = {Performance evaluation,TAU,analysis,instrumentation,measurement},
mendeley-groups = {HPCMASPA},
number = {2},
pages = {287--311},
title = {{The Tau Parallel Performance System}},
volume = {20},
year = {2006}
}
@incollection{Knupfer2012,
author = {Kn{\"{u}}pfer, Andreas and R{\"{o}}ssel, Christian and an Mey, Dieter and Biersdorff, Scott and Diethelm, Kai and Eschweiler, Dominic and Geimer, Markus and Gerndt, Michael and Lorenz, Daniel and Malony, Allen and Nagel, Wolfgang E. and Oleynik, Yury and Philippen, Peter and Saviankou, Pavel and Schmidl, Dirk and Shende, Sameer and Tsch{\"{u}}ter, Ronny and Wagner, Michael and Wesarg, Bert and Wolf, Felix},
booktitle = {Tools for High Performance Computing},
doi = {10.1007/978-3-642-31476-6_7},
file = {:Users/keichi/Documents/Mendeley Desktop/Kn{\"{u}}pfer et al. - 2012 - Score-P A Joint Performance Measurement Run-Time Infrastructure for Periscope, Scalasca, TAU, and Vampir.pdf:pdf},
mendeley-groups = {HPCMASPA},
pages = {79--91},
title = {{Score-P: A Joint Performance Measurement Run-Time Infrastructure for Periscope, Scalasca, TAU, and Vampir}},
year = {2012}
}
@inproceedings{Jo2015,
abstract = {The fat tree topology with multipath capability has been used in many recent data center networks (DCNs) for increased bandwidth and fault tolerance. Traditional routing protocols have only limited support for multipath routing, and cannot fully utilize the available bandwidth in such networks. In this paper, we study multipath routing for fat tree networks. We formulate the problem as a linear program and prove its NP-completeness. We propose a practical solution, which takes advantage of the emerging software-defined networking paradigm. Our algorithm relies on a central controller to collect necessary network state information in order to make optimized routing decisions. We implemented the algorithm as an OpenFlow controller module and validated it with Mininet emulation. We also developed a fluid-based DCN simulator and conducted experiments, which show that our algorithm outperforms the traditional multipath algorithm based on random assignments, both in terms of increased throughput and in reduced end-to-end delay.},
author = {Jo, Eric and Pan, Deng and Liu, Jason and Butler, Linda},
booktitle = {2014 Winter Simulation Conference (WSC 2014)},
doi = {10.1109/WSC.2014.7020145},
file = {:Users/keichi/Documents/Mendeley Desktop/07020145.pdf:pdf},
mendeley-groups = {HPCMASPA},
pages = {3072--3083},
title = {{A Simulation and Emulation Study of SDN-based Multipath Routing for Fat-tree Data Center Networks}},
year = {2015}
}
@inproceedings{Hoefler2011,
abstract = {The steadily increasing number of nodes in high-performance computing systems and the technology and power constraints lead to sparse network topologies. Efficient mapping of ap- plication communication patterns to the network topology gains importance as systems grow to petascale and beyond. Such mapping is supported in parallel programming frame- works such as MPI, but is often not well implemented. We show that the topology mapping problem is NP-complete and analyze and compare different practical topology map- ping heuristics. We demonstrate an efficient and fast new heuristic which is based on graph similarity and show its util- ity with application communication patterns on real topolo- gies. Our mapping strategies support heterogeneous net- works and show significant reduction of congestion on torus, fat-tree, and the PERCS network topologies, for irregular communication patterns. We also demonstrate that the ben- efit of topology mapping grows with the network size and show how our algorithms can be used in a practical setting to optimize communication performance. Our efficient topol- ogy mapping strategies are shown to reduce network con- gestion by up to 80{\%}, reduce average dilation by up to 50{\%}, and improve benchmarked communication performance by 18{\%}.},
author = {Hoefler, Torsten and Snir, Marc},
booktitle = {International Conference on Supercomputing - ICS '11},
doi = {10.1145/1995896.1995909},
file = {:Users/keichi/Documents/Mendeley Desktop/Hoefler, Snir - 2011 - Generic topology mapping strategies for large-scale parallel architectures.pdf:pdf},
isbn = {9781450301022},
keywords = {mpi graph topologies,topology mapping},
mendeley-groups = {Seminar,HPCMASPA},
pages = {75},
title = {{Generic Topology Mapping Strategies for Large-scale Parallel Architectures}},
url = {http://portal.acm.org/citation.cfm?doid=1995896.1995909},
year = {2011}
}
@article{Alawneh2016,
abstract = {The understanding of the interactions among processes of a High Performance Computing (HPC) system can be made easier if trace analysis is used. Traces, however, can be quite large, making it difficult to analyze their content unless some abstraction is provided. This paper presents a novel trace abstraction approach that aims to facilitate the analysis of large execution traces generated from HPC applications. Our approach allows automatic segmentation of large traces into smaller and meaningful clusters that reflect the various execution phases of the traced scenarios. Our approach is based on the application of information theory principles to the analysis of sequences of communication patterns extracted from traces of HPC systems. This work is inspired by recent studies in the field of bioinformatics where several techniques have been proposed to segment DNA sequences into homogeneous sub-domains, where each sub-domain exhibits a certain degree of internal homogeneity. Trace segments can be used in a number of applications such as recovering high-level views of the system behavior and program understanding. We demonstrate the usefulness of our approach by applying it to different traces of hundreds of millions of events, generated from two HPC systems.},
author = {Alawneh, Luay and Hamou-Lhadj, Abdelwahab and Hassine, Jameleddine},
doi = {10.1016/j.jss.2016.06.067},
file = {:Users/keichi/Documents/Mendeley Desktop/Alawneh, Hamou-Lhadj, Hassine - 2016 - Segmenting large traces of inter-process communication with a focus on high performance computing.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Dynamic analysis,High performance computing systems,Inter-process communication traces,Program comprehension,Software maintenance,Trace abstraction and analysis},
mendeley-groups = {To Read,HPCMASPA},
pages = {1--16},
title = {{Segmenting Large Traces of Inter-process Communication with a Focus on High Performance Computing Systems}},
volume = {120},
year = {2016}
}
@misc{Jones2006,
abstract = {This document describes an interface extension to the MPI-2 standard. The interface exposes useful information about an MPI implementation's internal state. The interface is appropriate for those who require an increased understanding of MPI internals such as those developing parallel development application tools.},
author = {Jones, Terry},
file = {:Users/keichi/Documents/Mendeley Desktop/Jones - 2006 - MPI PERUSE An MPI Extension for Revealing Unexposed Implementation Information.pdf:pdf},
mendeley-groups = {Next,HPCMASPA},
pages = {1--66},
title = {{MPI PERUSE: An MPI Extension for Revealing Unexposed Implementation Information}},
year = {2006}
}
@article{Jain2016,
author = {Jain, Nikhil and Bhatele, Abhinav and White, Sam and Gamblin, Todd and Kale, Laxmikant V},
file = {:Users/keichi/Documents/Mendeley Desktop/Jain et al. - 2016 - Evaluating HPC Networks via Simulation of Parallel Workloads.pdf:pdf},
isbn = {9781467388153},
mendeley-groups = {Next,HPCMASPA},
number = {November},
title = {{Evaluating HPC Networks via Simulation of Parallel Workloads}},
year = {2016}
}
@article{Schneider2009,
author = {Schneider, Timo and Hoefler, Torsten},
file = {:Users/keichi/Documents/Mendeley Desktop/Schneider, Hoefler - 2009 - Orcs An oblivious routing congestion simulator.pdf:pdf},
journal = {Indiana University, Computer},
mendeley-groups = {Next,HPCMASPA},
number = {675},
title = {{ORCS: An Oblivious Routing Congestion Simulator}},
year = {2009}
}
@inproceedings{Tikir2009,
abstract = {As the size of today{\&}{\#}x02019;s supercomputers grow exponentially in numbers of processors, the applications that run on these systems scale to larger processor counts. The majority of these applications commonly use Message Passing Interface (MPI); a trace of these MPI communication events is an important input to the tools that visualize, simulate for performance modeling, or enable tuning of parallel applications. We introduce an efficient, accurate and flexible trace-driven performance modeling and prediction tool, PMaC{\&}{\#}x02019;s Open Source Interconnect and Network Simulator (PSINS), for MPI applications. A principal feature of PSINS is its usability for applications that scale up to large processor counts. PSINS generates compact and tractable event traces for fast and efficient simulations while producing accurate performance predictions. PSINS was incorporated into PMaC{\&}{\#}x02019;s automated performance prediction framework and used to model three applications from the High Performance Computing Modernization Program{\&}{\#}x02019;s (HPCMP) Technology Insertion 2009 (TI-09) application suite.},
author = {Tikir, Mustafa M. and Laurenzano, Michael A. and Carrington, Laura and Snavely, Allan},
booktitle = {Department of Defense High Performance Computing Modernization Program - Users Group Conference (HPCMP-UGC)},
doi = {10.1109/HPCMP-UGC.2009.73},
file = {:Users/keichi/Documents/Mendeley Desktop/Tikir et al. - 2009 - PSINS An open source event tracer and execution simulator.pdf:pdf},
keywords = {and supercomputers,high performance computing,message passing applications,performance prediction,trace-driven simulation},
mendeley-groups = {Next,HPCMASPA},
pages = {444--449},
title = {{PSINS: An Open Source Event Tracer and Execution Simulator}},
year = {2009}
}
@article{Keller2006,
abstract = {This paper describes the implementation, usage and experience with the MPI performance revealing extension interface (Peruse) into the Open MPI implementation. While the PMPI-interface allows timing MPI-functions through wrappers, it can not provide MPI-internal information on MPI-states and lower-level network performance. We introduce the general design criteria of the interface implementation and analyze the overhead generated by this functionality. To support performance evaluation of large-scale applications, tools for visualization are imperative. We extend the tracing library of the Paraver-toolkit to support tracing Peruse-events and show how this helps detecting performance bottlenecks. A test-suite and a real-world application are traced and visualized using Paraver. {\textcopyright} Springer-Verlag Berlin Heidelberg 2006.},
author = {Keller, R.a and Bosilca, G.b and Fagg, G.b and Resch, M.a and Dongarra, J.J.b},
doi = {10.1007/11846802_48},
file = {:Users/keichi/Documents/Mendeley Desktop/Keller et al. - 2006 - Implementation and usage of the PERUSE-interface in open MPI.pdf:pdf},
isbn = {978-3-540-39110-4},
issn = {16113349},
journal = {Lecture Notes in Computer Science},
mendeley-groups = {Next,HPCMASPA},
pages = {347--355},
title = {{Implementation and usage of the PERUSE-interface in open MPI}},
volume = {4192},
year = {2006}
}
@misc{InfiniBand2015,
author = {{InfiniBand Trade Association}},
mendeley-groups = {Past Papers/INDIS16,HPCMASPA},
title = {{InfiniBand Architecture Specification Release 1.3}},
year = {2015}
}
@misc{omb,
author = {{Ohio State University}},
mendeley-groups = {Past Papers/IPSJ OS,HPCMASPA},
title = {{OSU Micro Benchmark}},
url = {http://mvapich.cse.ohio-state.edu/benchmarks/}
}
@misc{MessagePassingInterfaceForum2015,
author = {{Message Passing Interface Forum}},
mendeley-groups = {Past Papers/IPSJ OS,HPCMASPA},
title = {{MPI: A Message-Passing Interface Standard}},
url = {http://www.mpi-forum.org/docs/mpi-3.1/mpi31-report.pdf},
year = {2015}
}
@inproceedings{Takahashi2014,
author = {Takahashi, Keichi and Khureltulga, Dashdavaa and Watashiba, Yasuhiro and Kido, Yoshiyuki and Date, Susumu and Shimojo, Shinji},
booktitle = {2014 International Conference on High Performance Computing {\&} Simulation (HPCS 2014)},
doi = {10.1109/HPCSim.2014.6903768},
mendeley-groups = {Past Papers/INDIS16,Past Papers/IPSJ OS,MPI,HPCMASPA},
pages = {784--792},
title = {{Performance Evaluation of SDN-enhanced MPI{\_}Allreduce on a Cluster System with Fat-tree Interconnect}},
year = {2014}
}
@inproceedings{Dashdavaa2013,
author = {Dashdavaa, Khureltulga and Date, Susumu and Yamanaka, Hiroaki and Kawai, Eiji and Watashiba, Yasuhiro and Ichikawa, Kohei and Abe, Hirotake and Shimojo, Shinji},
booktitle = {6th Workshop on UnConventional High Performance Computing (UCHPC2013)},
doi = {10.1007/978-3-642-54420-0_86},
mendeley-groups = {Past Papers/IPSJ OS,Past Papers/Bachelor Thesis,HPCMASPA},
pages = {885--894},
title = {{Architecture of a High-Speed MPI{\_}Bcast Leveraging Software-Defined Network}},
year = {2014}
}
@misc{sdn,
author = {{Open Networking Foundation}},
mendeley-groups = {Past Papers/IPSJ OS,Past Papers/Bachelor Thesis,HPCMASPA},
title = {{Software-Defined Networking: The New Norm for Networks}},
url = {https://www.opennetworking.org/images/stories/downloads/sdn-resources/white-papers/wp-sdn-newnorm.pdf},
year = {2012}
}
@incollection{Gabriel2004,
author = {Gabriel, Edgar and Fagg, GrahamE. and Bosilca, George and Angskun, Thara and Dongarra, JackJ. and Squyres, JeffreyM. and Sahay, Vishal and Kambadur, Prabhanjan and Barrett, Brian and Lumsdaine, Andrew and Castain, RalphH. and Daniel, DavidJ. and Graham, RichardL. and Woodall, TimothyS.},
booktitle = {Recent Advances in Parallel Virtual Machine and Message Passing Interface SE  - 19},
doi = {10.1007/978-3-540-30218-6_19},
editor = {Kranzlm{\"{u}}ller, Dieter and Kacsuk, P{\'{e}}ter and Dongarra, Jack},
isbn = {978-3-540-23163-9},
mendeley-groups = {Past Papers/Bachelor Thesis,HPCMASPA},
pages = {97--104},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Open MPI: Goals, Concept, and Design of a Next Generation MPI Implementation}},
url = {http://dx.doi.org/10.1007/978-3-540-30218-6{\_}19},
volume = {3241},
year = {2004}
}
